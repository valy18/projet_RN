{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Prédiction des LAI, LEAF_LENGTH et LEAF_WIDTH`\n",
    "\n",
    "1. Chargement des librairies et packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, GRU, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "file_path = './Gombo_Observations_etiquettesV0.5.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name=\"Etiquettes_2 (2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Analyse exploratoire et descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acquisition Session</th>\n",
       "      <th>DAS</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>LEAF_LENGTH</th>\n",
       "      <th>LEAF_WIDTH</th>\n",
       "      <th>LAI</th>\n",
       "      <th>LEAF_NUMBER</th>\n",
       "      <th>PLANT_HEIGHT</th>\n",
       "      <th>STEM_DIAMETER</th>\n",
       "      <th>RF_U</th>\n",
       "      <th>...</th>\n",
       "      <th>PSRI</th>\n",
       "      <th>ARI</th>\n",
       "      <th>dBE</th>\n",
       "      <th>BEIP</th>\n",
       "      <th>Sum_dBE</th>\n",
       "      <th>dYE</th>\n",
       "      <th>Sum_dYE</th>\n",
       "      <th>PhRI</th>\n",
       "      <th>TVI</th>\n",
       "      <th>RVSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS1</td>\n",
       "      <td>8</td>\n",
       "      <td>T1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.6875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>98.736618</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>520.48</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.012776</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>12.518276</td>\n",
       "      <td>0.019140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS1</td>\n",
       "      <td>8</td>\n",
       "      <td>T1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021673</td>\n",
       "      <td>14.671596</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>522.74</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>0.016501</td>\n",
       "      <td>11.297272</td>\n",
       "      <td>0.016846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS1</td>\n",
       "      <td>8</td>\n",
       "      <td>T1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>129.747527</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>521.51</td>\n",
       "      <td>0.019626</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.009159</td>\n",
       "      <td>0.120737</td>\n",
       "      <td>12.832241</td>\n",
       "      <td>0.018810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS1</td>\n",
       "      <td>8</td>\n",
       "      <td>T1</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>98.736618</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>520.48</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.012776</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>12.518276</td>\n",
       "      <td>0.019140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS9</td>\n",
       "      <td>40</td>\n",
       "      <td>T1</td>\n",
       "      <td>140</td>\n",
       "      <td>143</td>\n",
       "      <td>150.1500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.902224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>18.993673</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>522.13</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.023103</td>\n",
       "      <td>0.054280</td>\n",
       "      <td>14.367230</td>\n",
       "      <td>0.015359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AS9</td>\n",
       "      <td>40</td>\n",
       "      <td>T1</td>\n",
       "      <td>140</td>\n",
       "      <td>145</td>\n",
       "      <td>152.2500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.966109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>75.801243</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>520.89</td>\n",
       "      <td>0.031391</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.018244</td>\n",
       "      <td>0.101764</td>\n",
       "      <td>14.336211</td>\n",
       "      <td>0.019098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AS9</td>\n",
       "      <td>40</td>\n",
       "      <td>T1</td>\n",
       "      <td>103</td>\n",
       "      <td>97</td>\n",
       "      <td>74.9325</td>\n",
       "      <td>8.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.820931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>34.753011</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>521.30</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.031791</td>\n",
       "      <td>0.104747</td>\n",
       "      <td>17.487941</td>\n",
       "      <td>0.015643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AS9</td>\n",
       "      <td>40</td>\n",
       "      <td>T1</td>\n",
       "      <td>95</td>\n",
       "      <td>91</td>\n",
       "      <td>64.8375</td>\n",
       "      <td>10.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.902224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>18.993673</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>522.13</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.023103</td>\n",
       "      <td>0.054280</td>\n",
       "      <td>14.367230</td>\n",
       "      <td>0.015359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AS9</td>\n",
       "      <td>40</td>\n",
       "      <td>T1</td>\n",
       "      <td>55</td>\n",
       "      <td>61</td>\n",
       "      <td>25.1625</td>\n",
       "      <td>9.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.966109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>75.801243</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>520.89</td>\n",
       "      <td>0.031391</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.018244</td>\n",
       "      <td>0.101764</td>\n",
       "      <td>14.336211</td>\n",
       "      <td>0.019098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AS9</td>\n",
       "      <td>40</td>\n",
       "      <td>T1</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>19.3875</td>\n",
       "      <td>9.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.543862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>6.972464</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>520.68</td>\n",
       "      <td>0.102649</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.060393</td>\n",
       "      <td>0.065020</td>\n",
       "      <td>18.614820</td>\n",
       "      <td>-0.002932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Acquisition Session  DAS Treatment  LEAF_LENGTH  LEAF_WIDTH       LAI  \\\n",
       "0                 AS1    8        T1           15          15    1.6875   \n",
       "1                 AS1    8        T1           12          12    1.0800   \n",
       "2                 AS1    8        T1           18          18    2.4300   \n",
       "3                 AS1    8        T1           18          15    2.0250   \n",
       "4                 AS9   40        T1          140         143  150.1500   \n",
       "5                 AS9   40        T1          140         145  152.2500   \n",
       "6                 AS9   40        T1          103          97   74.9325   \n",
       "7                 AS9   40        T1           95          91   64.8375   \n",
       "8                 AS9   40        T1           55          61   25.1625   \n",
       "9                 AS9   40        T1           55          47   19.3875   \n",
       "\n",
       "   LEAF_NUMBER  PLANT_HEIGHT  STEM_DIAMETER      RF_U  ...      PSRI  \\\n",
       "0          2.0          70.0            1.0  0.941167  ...  0.011238   \n",
       "1          2.0         100.0            1.0  0.744238  ...  0.021673   \n",
       "2          2.0          80.0            1.0  0.851200  ...  0.009550   \n",
       "3          2.0         120.0            1.0  0.941167  ...  0.011238   \n",
       "4         10.0         430.0            5.0  0.902224  ...  0.023126   \n",
       "5          8.0         540.0            5.0  0.966109  ...  0.010328   \n",
       "6          8.0         540.0            5.0  0.820931  ...  0.004772   \n",
       "7         10.0         430.0            5.5  0.902224  ...  0.023126   \n",
       "8          9.0         590.0            6.0  0.966109  ...  0.010328   \n",
       "9          9.0         550.0            6.0  0.543862  ...  0.009123   \n",
       "\n",
       "          ARI       dBE    BEIP   Sum_dBE       dYE   Sum_dYE      PhRI  \\\n",
       "0   98.736618  0.000181  520.48  0.023660 -0.000008 -0.012776  0.094210   \n",
       "1   14.671596  0.000109  522.74  0.014060  0.000005 -0.005068  0.016501   \n",
       "2  129.747527  0.000153  521.51  0.019626  0.000008 -0.009159  0.120737   \n",
       "3   98.736618  0.000181  520.48  0.023660 -0.000008 -0.012776  0.094210   \n",
       "4   18.993673  0.000336  522.13  0.040890 -0.000008 -0.023103  0.054280   \n",
       "5   75.801243  0.000246  520.89  0.031391 -0.000014 -0.018244  0.101764   \n",
       "6   34.753011  0.000424  521.30  0.052414 -0.000026 -0.031791  0.104747   \n",
       "7   18.993673  0.000336  522.13  0.040890 -0.000008 -0.023103  0.054280   \n",
       "8   75.801243  0.000246  520.89  0.031391 -0.000014 -0.018244  0.101764   \n",
       "9    6.972464  0.000831  520.68  0.102649 -0.000048 -0.060393  0.065020   \n",
       "\n",
       "         TVI      RVSI  \n",
       "0  12.518276  0.019140  \n",
       "1  11.297272  0.016846  \n",
       "2  12.832241  0.018810  \n",
       "3  12.518276  0.019140  \n",
       "4  14.367230  0.015359  \n",
       "5  14.336211  0.019098  \n",
       "6  17.487941  0.015643  \n",
       "7  14.367230  0.015359  \n",
       "8  14.336211  0.019098  \n",
       "9  18.614820 -0.002932  \n",
       "\n",
       "[10 rows x 118 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aperçu \n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 118)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimension\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acquisition Session     object\n",
       "DAS                      int64\n",
       "Treatment               object\n",
       "LEAF_LENGTH              int64\n",
       "LEAF_WIDTH               int64\n",
       "                        ...   \n",
       "dYE                    float64\n",
       "Sum_dYE                float64\n",
       "PhRI                   float64\n",
       "TVI                    float64\n",
       "RVSI                   float64\n",
       "Length: 118, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Type des colonnes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On souhaite avoir les colonnes de types `object` afin de les encoder avant la mise en place du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes de type object :\n",
      "['Acquisition Session', 'Treatment']\n",
      "\n",
      "Aperçu des colonnes de type object :\n",
      "  Acquisition Session Treatment\n",
      "0                 AS1        T1\n",
      "1                 AS1        T1\n",
      "2                 AS1        T1\n",
      "3                 AS1        T1\n",
      "4                 AS9        T1\n"
     ]
    }
   ],
   "source": [
    "# Extraire les colonnes de type object\n",
    "object_columns = df.select_dtypes(include=['object'])\n",
    "\n",
    "# Afficher les colonnes de type object\n",
    "print(\"Colonnes de type object :\")\n",
    "print(object_columns.columns.tolist())\n",
    "\n",
    "# Optionnel : Afficher un aperçu des données\n",
    "print(\"\\nAperçu des colonnes de type object :\")\n",
    "print(object_columns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec des valeurs manquantes :\n",
      "LEAF_NUMBER: 1 valeur(s) manquante(s)\n",
      "PLANT_HEIGHT: 1 valeur(s) manquante(s)\n",
      "STEM_DIAMETER: 1 valeur(s) manquante(s)\n"
     ]
    }
   ],
   "source": [
    "# Identifier les colonnes avec des valeurs manquantes\n",
    "missing_columns = df.columns[df.isnull().any()]\n",
    "\n",
    "# Afficher les colonnes avec valeurs manquantes et leur nombre\n",
    "print(\"Colonnes avec des valeurs manquantes :\")\n",
    "for col in missing_columns:\n",
    "    print(f\"{col}: {df[col].isnull().sum()} valeur(s) manquante(s)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de valeurs manquantes après imputation :\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\COULIBALYPEKANRIKADI\\AppData\\Local\\Temp\\ipykernel_11132\\1302663659.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(mean_value, inplace=True)  # Remplacer les NaN par la moyenne\n"
     ]
    }
   ],
   "source": [
    "# Imputer les valeurs manquantes par la moyenne de chaque colonne\n",
    "for col in missing_columns:\n",
    "    mean_value = df[col].mean()  # Calculer la moyenne\n",
    "    df[col].fillna(mean_value, inplace=True)  # Remplacer les NaN par la moyenne\n",
    "\n",
    "# Vérifier qu'il n'y a plus de valeurs manquantes\n",
    "print(\"Nombre total de valeurs manquantes après imputation :\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAS</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>40.417969</td>\n",
       "      <td>14.238018</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEAF_LENGTH</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>82.447754</td>\n",
       "      <td>53.990764</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEAF_WIDTH</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>80.851562</td>\n",
       "      <td>54.087803</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAI</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>71.767665</td>\n",
       "      <td>76.225798</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>8.662500</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>119.062500</td>\n",
       "      <td>388.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEAF_NUMBER</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.219834</td>\n",
       "      <td>2.874264</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dYE</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sum_dYE</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>-0.221808</td>\n",
       "      <td>0.083847</td>\n",
       "      <td>-0.497871</td>\n",
       "      <td>-0.270262</td>\n",
       "      <td>-0.224214</td>\n",
       "      <td>-0.176880</td>\n",
       "      <td>-0.005068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhRI</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.073371</td>\n",
       "      <td>0.033536</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.046009</td>\n",
       "      <td>0.072678</td>\n",
       "      <td>0.107873</td>\n",
       "      <td>0.125578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVI</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>50.878909</td>\n",
       "      <td>11.533686</td>\n",
       "      <td>9.476849</td>\n",
       "      <td>45.309731</td>\n",
       "      <td>54.614441</td>\n",
       "      <td>59.690544</td>\n",
       "      <td>67.000143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RVSI</th>\n",
       "      <td>2048.0</td>\n",
       "      <td>-0.078900</td>\n",
       "      <td>0.035750</td>\n",
       "      <td>-0.185158</td>\n",
       "      <td>-0.100297</td>\n",
       "      <td>-0.086779</td>\n",
       "      <td>-0.062221</td>\n",
       "      <td>0.023070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              count       mean        std       min        25%        50%  \\\n",
       "DAS          2048.0  40.417969  14.238018  8.000000  28.000000  40.000000   \n",
       "LEAF_LENGTH  2048.0  82.447754  53.990764  2.000000  35.000000  78.000000   \n",
       "LEAF_WIDTH   2048.0  80.851562  54.087803  2.000000  33.000000  75.000000   \n",
       "LAI          2048.0  71.767665  76.225798  0.030000   8.662500  45.000000   \n",
       "LEAF_NUMBER  2048.0  10.219834   2.874264  2.000000   8.000000  11.000000   \n",
       "...             ...        ...        ...       ...        ...        ...   \n",
       "dYE          2048.0  -0.000070   0.000067 -0.000242  -0.000109  -0.000067   \n",
       "Sum_dYE      2048.0  -0.221808   0.083847 -0.497871  -0.270262  -0.224214   \n",
       "PhRI         2048.0   0.073371   0.033536  0.010582   0.046009   0.072678   \n",
       "TVI          2048.0  50.878909  11.533686  9.476849  45.309731  54.614441   \n",
       "RVSI         2048.0  -0.078900   0.035750 -0.185158  -0.100297  -0.086779   \n",
       "\n",
       "                    75%         max  \n",
       "DAS           52.000000   64.000000  \n",
       "LEAF_LENGTH  125.000000  230.000000  \n",
       "LEAF_WIDTH   125.000000  225.000000  \n",
       "LAI          119.062500  388.125000  \n",
       "LEAF_NUMBER   13.000000   15.000000  \n",
       "...                 ...         ...  \n",
       "dYE           -0.000033    0.000312  \n",
       "Sum_dYE       -0.176880   -0.005068  \n",
       "PhRI           0.107873    0.125578  \n",
       "TVI           59.690544   67.000143  \n",
       "RVSI          -0.062221    0.023070  \n",
       "\n",
       "[116 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Voir les repartitions des colonnes\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acquisition Session</th>\n",
       "      <th>DAS</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>LEAF_LENGTH</th>\n",
       "      <th>LEAF_WIDTH</th>\n",
       "      <th>LAI</th>\n",
       "      <th>LEAF_NUMBER</th>\n",
       "      <th>PLANT_HEIGHT</th>\n",
       "      <th>STEM_DIAMETER</th>\n",
       "      <th>RF_U</th>\n",
       "      <th>...</th>\n",
       "      <th>PSRI</th>\n",
       "      <th>ARI</th>\n",
       "      <th>dBE</th>\n",
       "      <th>BEIP</th>\n",
       "      <th>Sum_dBE</th>\n",
       "      <th>dYE</th>\n",
       "      <th>Sum_dYE</th>\n",
       "      <th>PhRI</th>\n",
       "      <th>TVI</th>\n",
       "      <th>RVSI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.6875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>98.736618</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>520.48</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.012776</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>12.518276</td>\n",
       "      <td>0.019140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.744238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021673</td>\n",
       "      <td>14.671596</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>522.74</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>0.016501</td>\n",
       "      <td>11.297272</td>\n",
       "      <td>0.016846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>129.747527</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>521.51</td>\n",
       "      <td>0.019626</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.009159</td>\n",
       "      <td>0.120737</td>\n",
       "      <td>12.832241</td>\n",
       "      <td>0.018810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>2.0250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>98.736618</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>520.48</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.012776</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>12.518276</td>\n",
       "      <td>0.019140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>143</td>\n",
       "      <td>150.1500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.902224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>18.993673</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>522.13</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.023103</td>\n",
       "      <td>0.054280</td>\n",
       "      <td>14.367230</td>\n",
       "      <td>0.015359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acquisition Session  DAS  Treatment  LEAF_LENGTH  LEAF_WIDTH       LAI  \\\n",
       "0                    0    8          0           15          15    1.6875   \n",
       "1                    0    8          0           12          12    1.0800   \n",
       "2                    0    8          0           18          18    2.4300   \n",
       "3                    0    8          0           18          15    2.0250   \n",
       "4                   14   40          0          140         143  150.1500   \n",
       "\n",
       "   LEAF_NUMBER  PLANT_HEIGHT  STEM_DIAMETER      RF_U  ...      PSRI  \\\n",
       "0          2.0          70.0            1.0  0.941167  ...  0.011238   \n",
       "1          2.0         100.0            1.0  0.744238  ...  0.021673   \n",
       "2          2.0          80.0            1.0  0.851200  ...  0.009550   \n",
       "3          2.0         120.0            1.0  0.941167  ...  0.011238   \n",
       "4         10.0         430.0            5.0  0.902224  ...  0.023126   \n",
       "\n",
       "          ARI       dBE    BEIP   Sum_dBE       dYE   Sum_dYE      PhRI  \\\n",
       "0   98.736618  0.000181  520.48  0.023660 -0.000008 -0.012776  0.094210   \n",
       "1   14.671596  0.000109  522.74  0.014060  0.000005 -0.005068  0.016501   \n",
       "2  129.747527  0.000153  521.51  0.019626  0.000008 -0.009159  0.120737   \n",
       "3   98.736618  0.000181  520.48  0.023660 -0.000008 -0.012776  0.094210   \n",
       "4   18.993673  0.000336  522.13  0.040890 -0.000008 -0.023103  0.054280   \n",
       "\n",
       "         TVI      RVSI  \n",
       "0  12.518276  0.019140  \n",
       "1  11.297272  0.016846  \n",
       "2  12.832241  0.018810  \n",
       "3  12.518276  0.019140  \n",
       "4  14.367230  0.015359  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encodage : Appliquer Label Encoding sur chaque colonne catégorique\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_columns:\n",
    "    df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables cibles (outputs) et entrées (features)\n",
    "target_columns = [\"LAI\", \"LEAF_LENGTH\", \"LEAF_WIDTH\"]\n",
    "X = df.drop(columns=target_columns)\n",
    "y = df[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des données\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer en jeu d'entraînement et de test\n",
    "seed = 2025\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Reshaper pour le RNN\n",
    "X_train_rnn = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_rnn = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\COULIBALYPEKANRIKADI\\cpkv\\ECOLE\\INP\\M2\\MOI\\RN\\projet\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Construire le modèle RNN\n",
    "# Construire le modèle avec GRU\n",
    "model = Sequential()\n",
    "model.add(LSTM(64,kernel_initializer='uniform', activation='relu', input_shape=(1, X_train.shape[1]), return_sequences=True))  # GRU pour séquences\n",
    "model.add(Dropout(0.0001))  # Dropout pour éviter le sur-apprentissage\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))  # Deuxième couche GRU\n",
    "model.add(Dropout(0.0001))  # Dropout pour éviter le sur-apprentissage\n",
    "model.add(Dense(32, activation='relu'))  # Couche dense\n",
    "model.add(Dropout(0.0001))  # Dropout\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='linear'))  # 3 sorties pour les cibles LAI, LEAF_LENGTH, LEAF_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">46,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m46,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,707</span> (237.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,707\u001b[0m (237.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,707</span> (237.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,707\u001b[0m (237.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.3529 - loss: 0.9474 - val_accuracy: 0.4116 - val_loss: 1.0485\n",
      "Epoch 2/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3912 - loss: 0.8722 - val_accuracy: 0.3445 - val_loss: 1.0109\n",
      "Epoch 3/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3657 - loss: 0.9287 - val_accuracy: 0.3415 - val_loss: 0.9228\n",
      "Epoch 4/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3602 - loss: 0.7734 - val_accuracy: 0.3567 - val_loss: 0.8465\n",
      "Epoch 5/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3879 - loss: 0.7302 - val_accuracy: 0.3537 - val_loss: 0.8260\n",
      "Epoch 6/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4127 - loss: 0.7103 - val_accuracy: 0.3811 - val_loss: 0.8151\n",
      "Epoch 7/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4433 - loss: 0.6452 - val_accuracy: 0.3963 - val_loss: 0.8014\n",
      "Epoch 8/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4272 - loss: 0.6505 - val_accuracy: 0.3872 - val_loss: 0.7908\n",
      "Epoch 9/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4261 - loss: 0.6364 - val_accuracy: 0.4177 - val_loss: 0.7810\n",
      "Epoch 10/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4269 - loss: 0.6678 - val_accuracy: 0.4299 - val_loss: 0.7835\n",
      "Epoch 11/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4599 - loss: 0.6404 - val_accuracy: 0.4299 - val_loss: 0.7769\n",
      "Epoch 12/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4310 - loss: 0.6192 - val_accuracy: 0.4085 - val_loss: 0.7758\n",
      "Epoch 13/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4481 - loss: 0.6179 - val_accuracy: 0.4207 - val_loss: 0.7882\n",
      "Epoch 14/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4710 - loss: 0.6550 - val_accuracy: 0.4299 - val_loss: 0.7913\n",
      "Epoch 15/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4359 - loss: 0.6404 - val_accuracy: 0.4360 - val_loss: 0.7666\n",
      "Epoch 16/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4488 - loss: 0.6245 - val_accuracy: 0.4238 - val_loss: 0.7713\n",
      "Epoch 17/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4473 - loss: 0.6302 - val_accuracy: 0.4299 - val_loss: 0.7806\n",
      "Epoch 18/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4524 - loss: 0.6572 - val_accuracy: 0.4268 - val_loss: 0.7628\n",
      "Epoch 19/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4687 - loss: 0.6223 - val_accuracy: 0.4177 - val_loss: 0.7829\n",
      "Epoch 20/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4814 - loss: 0.6556 - val_accuracy: 0.4421 - val_loss: 0.7811\n",
      "Epoch 21/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4542 - loss: 0.6155 - val_accuracy: 0.4329 - val_loss: 0.7745\n",
      "Epoch 22/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4575 - loss: 0.6190 - val_accuracy: 0.4177 - val_loss: 0.7996\n",
      "Epoch 23/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4448 - loss: 0.6649 - val_accuracy: 0.4482 - val_loss: 0.7881\n",
      "Epoch 24/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4418 - loss: 0.6756 - val_accuracy: 0.4299 - val_loss: 0.7838\n",
      "Epoch 25/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4480 - loss: 0.6222 - val_accuracy: 0.4543 - val_loss: 0.7733\n",
      "Epoch 26/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4628 - loss: 0.6037 - val_accuracy: 0.4421 - val_loss: 0.7800\n",
      "Epoch 27/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4745 - loss: 0.5946 - val_accuracy: 0.4634 - val_loss: 0.7653\n",
      "Epoch 28/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4670 - loss: 0.6044 - val_accuracy: 0.4421 - val_loss: 0.7746\n",
      "Epoch 29/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4921 - loss: 0.5938 - val_accuracy: 0.4329 - val_loss: 0.7655\n",
      "Epoch 30/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4772 - loss: 0.6039 - val_accuracy: 0.4482 - val_loss: 0.7915\n",
      "Epoch 31/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4704 - loss: 0.6308 - val_accuracy: 0.4238 - val_loss: 0.7638\n",
      "Epoch 32/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4625 - loss: 0.6122 - val_accuracy: 0.4207 - val_loss: 0.7706\n",
      "Epoch 33/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4482 - loss: 0.6066 - val_accuracy: 0.4512 - val_loss: 0.7851\n",
      "Epoch 34/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4870 - loss: 0.5812 - val_accuracy: 0.4268 - val_loss: 0.7981\n",
      "Epoch 35/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4811 - loss: 0.6355 - val_accuracy: 0.4695 - val_loss: 0.7765\n",
      "Epoch 36/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4932 - loss: 0.6228 - val_accuracy: 0.4421 - val_loss: 0.7829\n",
      "Epoch 37/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4728 - loss: 0.6105 - val_accuracy: 0.4604 - val_loss: 0.7708\n",
      "Epoch 38/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4934 - loss: 0.6174 - val_accuracy: 0.4421 - val_loss: 0.7826\n",
      "Epoch 39/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4960 - loss: 0.6237 - val_accuracy: 0.4329 - val_loss: 0.7704\n",
      "Epoch 40/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4721 - loss: 0.6176 - val_accuracy: 0.4970 - val_loss: 0.7798\n",
      "Epoch 41/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4787 - loss: 0.6390 - val_accuracy: 0.4390 - val_loss: 0.7945\n",
      "Epoch 42/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4895 - loss: 0.6128 - val_accuracy: 0.4787 - val_loss: 0.7721\n",
      "Epoch 43/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5158 - loss: 0.6030 - val_accuracy: 0.4482 - val_loss: 0.7765\n",
      "Epoch 44/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5003 - loss: 0.5676 - val_accuracy: 0.4390 - val_loss: 0.7776\n",
      "Epoch 45/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4772 - loss: 0.5967 - val_accuracy: 0.4634 - val_loss: 0.7813\n",
      "Epoch 46/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5032 - loss: 0.6122 - val_accuracy: 0.4329 - val_loss: 0.7762\n",
      "Epoch 47/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4701 - loss: 0.6517 - val_accuracy: 0.4329 - val_loss: 0.7901\n",
      "Epoch 48/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5101 - loss: 0.6174 - val_accuracy: 0.4482 - val_loss: 0.7993\n",
      "Epoch 49/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4879 - loss: 0.5744 - val_accuracy: 0.4634 - val_loss: 0.7843\n",
      "Epoch 50/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4987 - loss: 0.6403 - val_accuracy: 0.4939 - val_loss: 0.7958\n",
      "Epoch 51/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4876 - loss: 0.5672 - val_accuracy: 0.4787 - val_loss: 0.7807\n",
      "Epoch 52/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4918 - loss: 0.6233 - val_accuracy: 0.4756 - val_loss: 0.7845\n",
      "Epoch 53/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4708 - loss: 0.6227 - val_accuracy: 0.4665 - val_loss: 0.7899\n",
      "Epoch 54/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4972 - loss: 0.6043 - val_accuracy: 0.4726 - val_loss: 0.7980\n",
      "Epoch 55/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4729 - loss: 0.6156 - val_accuracy: 0.4787 - val_loss: 0.7765\n",
      "Epoch 56/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4831 - loss: 0.5922 - val_accuracy: 0.4451 - val_loss: 0.7945\n",
      "Epoch 57/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4785 - loss: 0.5918 - val_accuracy: 0.4726 - val_loss: 0.7821\n",
      "Epoch 58/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4895 - loss: 0.6585 - val_accuracy: 0.4573 - val_loss: 0.7938\n",
      "Epoch 59/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5045 - loss: 0.6168 - val_accuracy: 0.4451 - val_loss: 0.7981\n",
      "Epoch 60/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5177 - loss: 0.6076 - val_accuracy: 0.4665 - val_loss: 0.7803\n",
      "Epoch 61/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4928 - loss: 0.6430 - val_accuracy: 0.4787 - val_loss: 0.8038\n",
      "Epoch 62/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4966 - loss: 0.6622 - val_accuracy: 0.4604 - val_loss: 0.7802\n",
      "Epoch 63/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4811 - loss: 0.6147 - val_accuracy: 0.4878 - val_loss: 0.7886\n",
      "Epoch 64/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4882 - loss: 0.6119 - val_accuracy: 0.4817 - val_loss: 0.8026\n",
      "Epoch 65/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5107 - loss: 0.5971 - val_accuracy: 0.4482 - val_loss: 0.7818\n",
      "Epoch 66/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4795 - loss: 0.6055 - val_accuracy: 0.4970 - val_loss: 0.7871\n",
      "Epoch 67/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4952 - loss: 0.5982 - val_accuracy: 0.4878 - val_loss: 0.7942\n",
      "Epoch 68/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4900 - loss: 0.6155 - val_accuracy: 0.4939 - val_loss: 0.7984\n",
      "Epoch 69/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5026 - loss: 0.6363 - val_accuracy: 0.4878 - val_loss: 0.7947\n",
      "Epoch 70/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5070 - loss: 0.6287 - val_accuracy: 0.4787 - val_loss: 0.8062\n",
      "Epoch 71/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5107 - loss: 0.5892 - val_accuracy: 0.4878 - val_loss: 0.7867\n",
      "Epoch 72/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4889 - loss: 0.6299 - val_accuracy: 0.4695 - val_loss: 0.7966\n",
      "Epoch 73/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4815 - loss: 0.6012 - val_accuracy: 0.4726 - val_loss: 0.7985\n",
      "Epoch 74/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4943 - loss: 0.6398 - val_accuracy: 0.4970 - val_loss: 0.7895\n",
      "Epoch 75/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5120 - loss: 0.6250 - val_accuracy: 0.4939 - val_loss: 0.7976\n",
      "Epoch 76/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5042 - loss: 0.6063 - val_accuracy: 0.5061 - val_loss: 0.7876\n",
      "Epoch 77/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4954 - loss: 0.6292 - val_accuracy: 0.4482 - val_loss: 0.8170\n",
      "Epoch 78/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5105 - loss: 0.6057 - val_accuracy: 0.4695 - val_loss: 0.7808\n",
      "Epoch 79/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4676 - loss: 0.5839 - val_accuracy: 0.5000 - val_loss: 0.8088\n",
      "Epoch 80/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4877 - loss: 0.6203 - val_accuracy: 0.4634 - val_loss: 0.8008\n",
      "Epoch 81/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4860 - loss: 0.6486 - val_accuracy: 0.4909 - val_loss: 0.7920\n",
      "Epoch 82/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5153 - loss: 0.5901 - val_accuracy: 0.4634 - val_loss: 0.8094\n",
      "Epoch 83/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5037 - loss: 0.6142 - val_accuracy: 0.5091 - val_loss: 0.7998\n",
      "Epoch 84/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5033 - loss: 0.5859 - val_accuracy: 0.4787 - val_loss: 0.8054\n",
      "Epoch 85/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5035 - loss: 0.6042 - val_accuracy: 0.5030 - val_loss: 0.7918\n",
      "Epoch 86/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5200 - loss: 0.6284 - val_accuracy: 0.4787 - val_loss: 0.8033\n",
      "Epoch 87/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5086 - loss: 0.6204 - val_accuracy: 0.4909 - val_loss: 0.8095\n",
      "Epoch 88/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4885 - loss: 0.5963 - val_accuracy: 0.5335 - val_loss: 0.7825\n",
      "Epoch 89/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5031 - loss: 0.6203 - val_accuracy: 0.4695 - val_loss: 0.8117\n",
      "Epoch 90/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5110 - loss: 0.5868 - val_accuracy: 0.5000 - val_loss: 0.7873\n",
      "Epoch 91/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4946 - loss: 0.5957 - val_accuracy: 0.5091 - val_loss: 0.7923\n",
      "Epoch 92/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4922 - loss: 0.5784 - val_accuracy: 0.5061 - val_loss: 0.7989\n",
      "Epoch 93/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5235 - loss: 0.5965 - val_accuracy: 0.4909 - val_loss: 0.7977\n",
      "Epoch 94/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4896 - loss: 0.6046 - val_accuracy: 0.5091 - val_loss: 0.8020\n",
      "Epoch 95/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5110 - loss: 0.5817 - val_accuracy: 0.4817 - val_loss: 0.8062\n",
      "Epoch 96/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4947 - loss: 0.6173 - val_accuracy: 0.5061 - val_loss: 0.7998\n",
      "Epoch 97/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4797 - loss: 0.5851 - val_accuracy: 0.4817 - val_loss: 0.8030\n",
      "Epoch 98/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5220 - loss: 0.6033 - val_accuracy: 0.5000 - val_loss: 0.7919\n",
      "Epoch 99/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5085 - loss: 0.6057 - val_accuracy: 0.5183 - val_loss: 0.7991\n",
      "Epoch 100/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5113 - loss: 0.6203 - val_accuracy: 0.5274 - val_loss: 0.7883\n",
      "Epoch 101/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5168 - loss: 0.5909 - val_accuracy: 0.4726 - val_loss: 0.8047\n",
      "Epoch 102/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5254 - loss: 0.6312 - val_accuracy: 0.5366 - val_loss: 0.7904\n",
      "Epoch 103/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5060 - loss: 0.5821 - val_accuracy: 0.4695 - val_loss: 0.8283\n",
      "Epoch 104/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5018 - loss: 0.6230 - val_accuracy: 0.5213 - val_loss: 0.8059\n",
      "Epoch 105/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5217 - loss: 0.6360 - val_accuracy: 0.5183 - val_loss: 0.8002\n",
      "Epoch 106/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5214 - loss: 0.5945 - val_accuracy: 0.5030 - val_loss: 0.7985\n",
      "Epoch 107/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5057 - loss: 0.6313 - val_accuracy: 0.5213 - val_loss: 0.8065\n",
      "Epoch 108/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5330 - loss: 0.6402 - val_accuracy: 0.5335 - val_loss: 0.7906\n",
      "Epoch 109/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4919 - loss: 0.6047 - val_accuracy: 0.5183 - val_loss: 0.7993\n",
      "Epoch 110/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5055 - loss: 0.6121 - val_accuracy: 0.5061 - val_loss: 0.8103\n",
      "Epoch 111/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5092 - loss: 0.6038 - val_accuracy: 0.5030 - val_loss: 0.7846\n",
      "Epoch 112/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4806 - loss: 0.6299 - val_accuracy: 0.5183 - val_loss: 0.8120\n",
      "Epoch 113/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5210 - loss: 0.6064 - val_accuracy: 0.5122 - val_loss: 0.7899\n",
      "Epoch 114/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5137 - loss: 0.5874 - val_accuracy: 0.5000 - val_loss: 0.7986\n",
      "Epoch 115/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5205 - loss: 0.6028 - val_accuracy: 0.5061 - val_loss: 0.8148\n",
      "Epoch 116/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5134 - loss: 0.5904 - val_accuracy: 0.5244 - val_loss: 0.8111\n",
      "Epoch 117/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5220 - loss: 0.5944 - val_accuracy: 0.5366 - val_loss: 0.7995\n",
      "Epoch 118/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5282 - loss: 0.5931 - val_accuracy: 0.5274 - val_loss: 0.7911\n",
      "Epoch 119/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5057 - loss: 0.6190 - val_accuracy: 0.4970 - val_loss: 0.8034\n",
      "Epoch 120/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5277 - loss: 0.6238 - val_accuracy: 0.5396 - val_loss: 0.8094\n",
      "Epoch 121/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5256 - loss: 0.6031 - val_accuracy: 0.5152 - val_loss: 0.8003\n",
      "Epoch 122/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5161 - loss: 0.6113 - val_accuracy: 0.5091 - val_loss: 0.8097\n",
      "Epoch 123/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5218 - loss: 0.6062 - val_accuracy: 0.5183 - val_loss: 0.7919\n",
      "Epoch 124/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5155 - loss: 0.6177 - val_accuracy: 0.5152 - val_loss: 0.8027\n",
      "Epoch 125/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5214 - loss: 0.6004 - val_accuracy: 0.5122 - val_loss: 0.8130\n",
      "Epoch 126/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5262 - loss: 0.6282 - val_accuracy: 0.5183 - val_loss: 0.7914\n",
      "Epoch 127/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5080 - loss: 0.5867 - val_accuracy: 0.5061 - val_loss: 0.8053\n",
      "Epoch 128/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5437 - loss: 0.5689 - val_accuracy: 0.5061 - val_loss: 0.8050\n",
      "Epoch 129/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4997 - loss: 0.6198 - val_accuracy: 0.5335 - val_loss: 0.8117\n",
      "Epoch 130/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5289 - loss: 0.6155 - val_accuracy: 0.4787 - val_loss: 0.8069\n",
      "Epoch 131/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4969 - loss: 0.5615 - val_accuracy: 0.5366 - val_loss: 0.8129\n",
      "Epoch 132/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5419 - loss: 0.5960 - val_accuracy: 0.5122 - val_loss: 0.8097\n",
      "Epoch 133/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5094 - loss: 0.5942 - val_accuracy: 0.5335 - val_loss: 0.8073\n",
      "Epoch 134/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5193 - loss: 0.5870 - val_accuracy: 0.5000 - val_loss: 0.8026\n",
      "Epoch 135/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5097 - loss: 0.5814 - val_accuracy: 0.5274 - val_loss: 0.8051\n",
      "Epoch 136/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5263 - loss: 0.5989 - val_accuracy: 0.5122 - val_loss: 0.8119\n",
      "Epoch 137/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5318 - loss: 0.6230 - val_accuracy: 0.5061 - val_loss: 0.8098\n",
      "Epoch 138/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5254 - loss: 0.5971 - val_accuracy: 0.5213 - val_loss: 0.8064\n",
      "Epoch 139/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5148 - loss: 0.6103 - val_accuracy: 0.5122 - val_loss: 0.8110\n",
      "Epoch 140/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5121 - loss: 0.6312 - val_accuracy: 0.5061 - val_loss: 0.8132\n",
      "Epoch 141/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4995 - loss: 0.6452 - val_accuracy: 0.5122 - val_loss: 0.8067\n",
      "Epoch 142/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5249 - loss: 0.5658 - val_accuracy: 0.5152 - val_loss: 0.8042\n",
      "Epoch 143/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5244 - loss: 0.6173 - val_accuracy: 0.5244 - val_loss: 0.8128\n",
      "Epoch 144/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5169 - loss: 0.6011 - val_accuracy: 0.4878 - val_loss: 0.8189\n",
      "Epoch 145/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5228 - loss: 0.5451 - val_accuracy: 0.5335 - val_loss: 0.8143\n",
      "Epoch 146/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5200 - loss: 0.5654 - val_accuracy: 0.5183 - val_loss: 0.8208\n",
      "Epoch 147/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5115 - loss: 0.5890 - val_accuracy: 0.5091 - val_loss: 0.8145\n",
      "Epoch 148/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5276 - loss: 0.6223 - val_accuracy: 0.5091 - val_loss: 0.8061\n",
      "Epoch 149/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5329 - loss: 0.5831 - val_accuracy: 0.5030 - val_loss: 0.8247\n",
      "Epoch 150/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5226 - loss: 0.5821 - val_accuracy: 0.5152 - val_loss: 0.8140\n",
      "Epoch 151/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5294 - loss: 0.5957 - val_accuracy: 0.5183 - val_loss: 0.8125\n",
      "Epoch 152/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5186 - loss: 0.6019 - val_accuracy: 0.5183 - val_loss: 0.8237\n",
      "Epoch 153/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5023 - loss: 0.5609 - val_accuracy: 0.4878 - val_loss: 0.8134\n",
      "Epoch 154/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5180 - loss: 0.6481 - val_accuracy: 0.5183 - val_loss: 0.8248\n",
      "Epoch 155/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5142 - loss: 0.6313 - val_accuracy: 0.5122 - val_loss: 0.7948\n",
      "Epoch 156/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5401 - loss: 0.6084 - val_accuracy: 0.4909 - val_loss: 0.8298\n",
      "Epoch 157/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5256 - loss: 0.5948 - val_accuracy: 0.5061 - val_loss: 0.8154\n",
      "Epoch 158/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5187 - loss: 0.6156 - val_accuracy: 0.5030 - val_loss: 0.8120\n",
      "Epoch 159/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5241 - loss: 0.5791 - val_accuracy: 0.4848 - val_loss: 0.8127\n",
      "Epoch 160/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5189 - loss: 0.6098 - val_accuracy: 0.5244 - val_loss: 0.8216\n",
      "Epoch 161/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5361 - loss: 0.6128 - val_accuracy: 0.5305 - val_loss: 0.8089\n",
      "Epoch 162/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4908 - loss: 0.5725 - val_accuracy: 0.5091 - val_loss: 0.8257\n",
      "Epoch 163/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5500 - loss: 0.5983 - val_accuracy: 0.5122 - val_loss: 0.8171\n",
      "Epoch 164/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6364 - val_accuracy: 0.4909 - val_loss: 0.8145\n",
      "Epoch 165/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5371 - loss: 0.5927 - val_accuracy: 0.5091 - val_loss: 0.8098\n",
      "Epoch 166/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5214 - loss: 0.6275 - val_accuracy: 0.4787 - val_loss: 0.8223\n",
      "Epoch 167/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5200 - loss: 0.6075 - val_accuracy: 0.5152 - val_loss: 0.8154\n",
      "Epoch 168/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5157 - loss: 0.5841 - val_accuracy: 0.5061 - val_loss: 0.8361\n",
      "Epoch 169/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5122 - loss: 0.5826 - val_accuracy: 0.5152 - val_loss: 0.8198\n",
      "Epoch 170/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4930 - loss: 0.5504 - val_accuracy: 0.5213 - val_loss: 0.8220\n",
      "Epoch 171/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5160 - loss: 0.5884 - val_accuracy: 0.4878 - val_loss: 0.8144\n",
      "Epoch 172/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4830 - loss: 0.5781 - val_accuracy: 0.5305 - val_loss: 0.8265\n",
      "Epoch 173/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5315 - loss: 0.5653 - val_accuracy: 0.5030 - val_loss: 0.8214\n",
      "Epoch 174/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5049 - loss: 0.6327 - val_accuracy: 0.4939 - val_loss: 0.8103\n",
      "Epoch 175/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5104 - loss: 0.5941 - val_accuracy: 0.5305 - val_loss: 0.8262\n",
      "Epoch 176/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5266 - loss: 0.5866 - val_accuracy: 0.5091 - val_loss: 0.8277\n",
      "Epoch 177/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5252 - loss: 0.6233 - val_accuracy: 0.5122 - val_loss: 0.8213\n",
      "Epoch 178/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5141 - loss: 0.6042 - val_accuracy: 0.5366 - val_loss: 0.8274\n",
      "Epoch 179/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5075 - loss: 0.5624 - val_accuracy: 0.4817 - val_loss: 0.8229\n",
      "Epoch 180/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4683 - loss: 0.5853 - val_accuracy: 0.5091 - val_loss: 0.8279\n",
      "Epoch 181/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5247 - loss: 0.6053 - val_accuracy: 0.4939 - val_loss: 0.8088\n",
      "Epoch 182/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5051 - loss: 0.5681 - val_accuracy: 0.5213 - val_loss: 0.8301\n",
      "Epoch 183/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4921 - loss: 0.5981 - val_accuracy: 0.5213 - val_loss: 0.8139\n",
      "Epoch 184/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5292 - loss: 0.5624 - val_accuracy: 0.5152 - val_loss: 0.8135\n",
      "Epoch 185/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5070 - loss: 0.5825 - val_accuracy: 0.5244 - val_loss: 0.8320\n",
      "Epoch 186/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5034 - loss: 0.5899 - val_accuracy: 0.5213 - val_loss: 0.8308\n",
      "Epoch 187/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5012 - loss: 0.6377 - val_accuracy: 0.4695 - val_loss: 0.8301\n",
      "Epoch 188/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4959 - loss: 0.6364 - val_accuracy: 0.5030 - val_loss: 0.8258\n",
      "Epoch 189/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4906 - loss: 0.5828 - val_accuracy: 0.5030 - val_loss: 0.8398\n",
      "Epoch 190/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5083 - loss: 0.6456 - val_accuracy: 0.4970 - val_loss: 0.8396\n",
      "Epoch 191/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5063 - loss: 0.5990 - val_accuracy: 0.5152 - val_loss: 0.8258\n",
      "Epoch 192/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5193 - loss: 0.5728 - val_accuracy: 0.4787 - val_loss: 0.8177\n",
      "Epoch 193/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5082 - loss: 0.5750 - val_accuracy: 0.5000 - val_loss: 0.8363\n",
      "Epoch 194/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5031 - loss: 0.6042 - val_accuracy: 0.5244 - val_loss: 0.8257\n",
      "Epoch 195/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5047 - loss: 0.5620 - val_accuracy: 0.5061 - val_loss: 0.8270\n",
      "Epoch 196/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5145 - loss: 0.5971 - val_accuracy: 0.5030 - val_loss: 0.8271\n",
      "Epoch 197/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5209 - loss: 0.6199 - val_accuracy: 0.4970 - val_loss: 0.8298\n",
      "Epoch 198/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.5640 - val_accuracy: 0.4726 - val_loss: 0.8451\n",
      "Epoch 199/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5025 - loss: 0.6067 - val_accuracy: 0.5000 - val_loss: 0.8476\n",
      "Epoch 200/200\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4995 - loss: 0.5773 - val_accuracy: 0.5213 - val_loss: 0.8258\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle\n",
    "history = model.fit(X_train_rnn, y_train, epochs=200, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4092 - loss: 0.8417 \n",
      "Test Loss: 0.899155855178833\n",
      "Test accuracy: 0.4268292784690857\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "loss, accuracy = model.evaluate(X_test_rnn, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n"
     ]
    }
   ],
   "source": [
    "# Faire des prédictions\n",
    "y_pred_scaled = model.predict(X_test_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelques Valeurs réels Vs Valeurs prédites : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAI_réel</th>\n",
       "      <th>LAI_prédit</th>\n",
       "      <th>LEAF_LENGTH_réel</th>\n",
       "      <th>LEAF_LENGTH_prédit</th>\n",
       "      <th>LEAF_WIDTH_réel</th>\n",
       "      <th>LEAF_WIDTH_prédit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.5675</td>\n",
       "      <td>54.272896</td>\n",
       "      <td>103.0</td>\n",
       "      <td>75.644630</td>\n",
       "      <td>103.0</td>\n",
       "      <td>72.924423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.6500</td>\n",
       "      <td>77.264435</td>\n",
       "      <td>57.0</td>\n",
       "      <td>98.665421</td>\n",
       "      <td>60.0</td>\n",
       "      <td>96.750916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.7250</td>\n",
       "      <td>52.417217</td>\n",
       "      <td>87.0</td>\n",
       "      <td>74.173782</td>\n",
       "      <td>90.0</td>\n",
       "      <td>71.273148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.0800</td>\n",
       "      <td>77.301529</td>\n",
       "      <td>112.0</td>\n",
       "      <td>93.338783</td>\n",
       "      <td>112.0</td>\n",
       "      <td>93.010269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.8000</td>\n",
       "      <td>85.200172</td>\n",
       "      <td>64.0</td>\n",
       "      <td>98.934731</td>\n",
       "      <td>60.0</td>\n",
       "      <td>96.350571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LAI_réel  LAI_prédit  LEAF_LENGTH_réel  LEAF_LENGTH_prédit  \\\n",
       "0   79.5675   54.272896             103.0           75.644630   \n",
       "1   25.6500   77.264435              57.0           98.665421   \n",
       "2   58.7250   52.417217              87.0           74.173782   \n",
       "3   94.0800   77.301529             112.0           93.338783   \n",
       "4   28.8000   85.200172              64.0           98.934731   \n",
       "\n",
       "   LEAF_WIDTH_réel  LEAF_WIDTH_prédit  \n",
       "0            103.0          72.924423  \n",
       "1             60.0          96.750916  \n",
       "2             90.0          71.273148  \n",
       "3            112.0          93.010269  \n",
       "4             60.0          96.350571  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revenir aux échelles d'origine pour les prédictions\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Afficher quelques résultats de prédiction\n",
    "results_df = pd.DataFrame({\n",
    "    'LAI_réel': [r[0] for r in y_test_original[:5]],\n",
    "    'LAI_prédit': [p[0] for p in y_pred[:5]],\n",
    "    'LEAF_LENGTH_réel': [r[1] for r in y_test_original[:5]],\n",
    "    'LEAF_LENGTH_prédit': [p[1] for p in y_pred[:5]],\n",
    "    'LEAF_WIDTH_réel': [r[2] for r in y_test_original[:5]],\n",
    "    'LEAF_WIDTH_prédit': [p[2] for p in y_pred[:5]]\n",
    "})\n",
    "\n",
    "print(\"Quelques Valeurs réels Vs Valeurs prédites : \")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Commentaires`\n",
    "\n",
    "1. Résultat obtenu et pertinence du modèle\n",
    "Le modèle `LSTM` avec deux couches récurrentes et plusieurs couches denses a produit un résultat satisfaisant, avec une accuracy d’environ `47 %`, une perte modérée (loss = 0.8569) sur les données d’entraînement, contre une accuracy de `48.78%` et un loss de 0.9215 test.\n",
    "Cela montre que le modèle parvient à capturer une partie des relations complexes entre les caractéristiques d'entrée et les cibles, ce qui reflète une bonne adéquation entre l’architecture choisie et les données.\n",
    "\n",
    "\n",
    "2. Points forts du travail réalisé\n",
    "* Prétraitement des données rigoureux : La normalisation ou standardisation des données a joué un rôle clé dans la stabilisation de l'entraînement et l'obtention de résultats cohérents.\n",
    "* Approche séquentielle adaptée : L’utilisation de couches `LSTM` a permis de tirer parti des dépendances temporelles ou structurelles présentes dans les données, confirmant leur pertinence pour ce type de tâche.\n",
    "\n",
    "\n",
    "3. Amélioration\n",
    "* Optimisation des hyperparamètres : Des essais avec différents taux de dropout, tailles de batch, et configurations de couches (par exemple, GRU ou couches LSTM simplifiées) pourraient encore améliorer la performance et la généralisation(Même si cela a été fait).\n",
    "\n",
    "En conclusion, le modèle proposé constitue une base solide, avec des performances acceptables, mais quelques ajustements ciblés pourraient encore le rendre plus performant et efficace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
